{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intro_text = ('This tutorial is about Natural Language Processing in Spacy.')\n",
    "introduction_doc = nlp(intro_text)\n",
    "# Extract tokens for the given doc\n",
    "print([token.text for token in introduction_doc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = 'SiemensP23.txt'\n",
    "text_file = open(file_name).read()\n",
    "doc = nlp(text_file)\n",
    "print('Number of tokens:', len(doc))\n",
    "\n",
    "# Extract tokens for the given doc\n",
    "print([token.text for token in doc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the sents property is used to extract sentences\n",
    "sentences = list(doc.sents)\n",
    "print('Anzahl sentences:', len(sentences))\n",
    "print('Satz 1:', sentences[27])\n",
    "print('Sentence is of type: ', type(sentences[27]))\n",
    "print('Size of \"sentences\":', len(sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "token = doc[2]\n",
    "print('The token:', token)\n",
    "print('Token (word) starts at character position:', token.idx)\n",
    "print('token text with trailing space (if present):', token.text_with_ws)\n",
    "print('if the token consists of alphabetic characters or not:', token.is_alpha)\n",
    "print('if the token is a punctuation symbol or not:', token.is_punct)\n",
    "print('if the token is a space or not:', token.is_space)\n",
    "print('prints out the shape of the word', token.shape_)\n",
    "print('if the token is a stop word or not:', token.is_stop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get rid of stop words\n",
    "no_stopword_doc = [token for token in doc if not token.is_stop]\n",
    "print(no_stopword_doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lemmatization: organizes, organized and organizing are all forms of organize. Here, organize is the lemma.\n",
    "for token in no_stopword_doc[:30]:\n",
    "    print(token, token.lemma_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter(doc)\n",
    "print(word_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# commonly occurring words with their frequencies\n",
    "num = 10\n",
    "common_words = word_freq.most_common(num)\n",
    "print(num, ' most common words:', common_words)\n",
    "\n",
    "# Unique words\n",
    "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
    "print('Unique words:', unique_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statistics\n",
    "from collections import Counter\n",
    "\n",
    "# Remove stop words and punctuation symbols\n",
    "words = [token.text for token in doc\n",
    "         if not token.is_stop and not token.is_punct]\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# 5 commonly occurring words with their frequencies\n",
    "common_words = word_freq.most_common(5)\n",
    "print(common_words)\n",
    "\n",
    "# Unique words\n",
    "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
    "print(unique_words)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Part of speech tagging is the process of assigning a POS tag to each token depending on its usage in the sentence.\n",
    "# POS tags are useful for assigning a syntactic category like noun or verb to each word.\n",
    "for token in doc[:20]:\n",
    "    print(token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Visualization: Using displaCy\n",
    "# from spacy import displacy\n",
    "# displacy.serve(sentences[27], style='dep')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Matching\n",
    "# from spacy.matcher import Matcher\n",
    "# matcher = Matcher(nlp.vocab)\n",
    "# conference_org_text = str('There is a developer conference'\n",
    "#     'happening on 21 July 2019 in London. It is titled'\n",
    "#     ' \"Applications of Natural Language Processing\".'\n",
    "#     ' There is a helpline number available'\n",
    "#     ' at (123) 456-789')\n",
    "#\n",
    "# def extract_phone_number(nlp_doc):\n",
    "#     pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
    "#                {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
    "#                {'ORTH': '-', 'OP': '?'},\n",
    "#                {'SHAPE': 'ddd'}]\n",
    "#     matcher.add(key='PHONE_NUMBER', patterns=pattern)\n",
    "#     matches = matcher(nlp_doc)\n",
    "#     for match_id, start, end in matches:\n",
    "#         span = nlp_doc[start:end]\n",
    "#         return span.text\n",
    "#\n",
    "# conference_org_doc = nlp(conference_org_text)\n",
    "# extract_phone_number(conference_org_doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Named Entity Recognition (NER) is the process of locating named entities in unstructured text and\n",
    "# then classifying them into pre-defined categories\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char,\n",
    "          ent.label_, spacy.explain(ent.label_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc[:1000], style='ent')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}